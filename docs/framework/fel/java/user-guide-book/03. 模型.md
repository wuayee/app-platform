# 聊天模型

聊天模型是 FEL 的核心组件，其使用聊天消息作为输入，并返回聊天消息作为输出。为方便集成不同模型提供商（OpenAI、Qwen 等）提供的模型服务，FEL 抽象了一个标准接口来进行交互，如下所示。

``` java
public interface ChatModel {
    /**
     * 调用聊天模型生成结果。
     *
     * @param prompt 表示提示词的 {@link Prompt}。
     * @param chatOption 表示聊天模型参数的 {@link ChatOption}。
     * @return 表示聊天模型生成结果的 {@link Choir}{@code <}{@link ChatMessage}{@code >}。
     */
    Choir<ChatMessage> generate(Prompt prompt, ChatOption chatOption);
}
```

聊天模型接收提示词以及一个可选参数，返回一个聊天消息流，根据可选参数中 `stream` 的值，返回一个或多个聊天消息。聊天模型的配置项如下表所示。

| 配置项| 描述 |
| --- | --- |
| model | 表示聊天模型名称。 |
| stream | 表示是否使用流式接口。|
| apiKey | 表示聊天模型接口密钥。 |
| maxTokens | 表示生成文本的最大长度。 |
| frequencyPenalty | 表示频率惩罚系数，取值范围为 [-2.0 - 2.0] 之间的数字，影响模型如何根据已存在文本的频率惩罚新文本；<br /> 正值将通过惩罚已经频繁使用的词来降低模型一行中重复用词的可能性；<br /> 为了稍微减少输出中的重复词语，惩罚系数的合理值通常约为 0.1 至 1；<br /> 如果目标是显著抑制重复，系数可以增加到 2，但这可能会对输出的质量产生负面影响；<br /> 相反，使用负值可以增加重复的可能性。<br /> </p> |
| presencePenalty | 表示文本出现惩罚系数，取值范围为 [-2.0 - 2.0] 之间的数字，影响模型如何根据到目前为止是否出现在文本中来惩罚新词汇；<br /> 正值将通过惩罚已经使用的词来增加模型谈论新主题的可能性；<br />  通常 presencePenalty 的默认值为 0，当希望使用输入中的单词生成与输入提示一致的文本时，使用该值；<br /> 另一方面，如果希望模型不受输入限制，那么可以使用更大的存在惩罚，这将鼓励模型生成输入中不存在的新词，  从而允许更多样化和创造性的输出；<br />  frequencyPenalty 和 presencePenalty 的不同点在于 frequencyPenalty 的惩罚会随着 token 出现的次数增加而不断加强， 而 presencePenalty 则只会区分是否出现。</p> |
| stop | 表示停止字符串列表，当模型输出中存在定义的字符串后，将会停止生成。 |
| temperature | 表示采样温度，取值范围为 [0.0 - 2.0] 之间的数字，控制生成的文本的多样性和随机性；<br /> 如果 temperature 值较高，则更倾向于生成随机的文本；如果值较低，则更倾向于生成相对可预测的文本； |
| topP | 表示采样率，取值范围为 [0.0 - 1.0] 之间的数字，表示模型考虑具有 topP 概率质量的令牌的结果，与 temperature 不建议同时设置；<br /> 例如： 0.1 意味着只考虑包含前 10% 概率质量的标记。 |
| tools | 表示模型能使用的工具列表。 |

调用聊天模型具体示例请看[《快速入门指南》](../quick-start-guide)的模型部分。

# 嵌入模型

嵌入模型（Embedding Model）是一类将文字、图像、声音等数据转换为高维向量空间中向量表示的模型。这种表示方法使得原始数据可以被模型以一种更加结构化和可处理的方式来分析，在理解、比较、分类和搜索复杂数据时发挥着重要作用。在 FEL 中，我们使用嵌入模型为查询和文档生成嵌入表示，随后计算查询和文档之间的向量相似度，以此找出最相关的结果。

``` java
public interface Embedding {
    /**
     * 获取嵌入向量。
     *
     * @return 表示嵌入向量的 {@link List}{@code <}{@link Float}{@code >}。
     */
    List<Float> embedding();
}

public interface EmbedModel {
    /**
     * 根据可选参数，调用嵌入模型生成嵌入向量。
     *
     * @param input 表示用户输入的 {@link String}。
     * @param option 表示嵌入模型可选参数的 {@link EmbedOption}。
     * @return 表示模型生成嵌入响应的 {@link Embedding}。
     */
    default Embedding generate(String input, EmbedOption option) {
        notBlank(input, "The input cannot be blank.");
        List<Embedding> embeddings = this.generate(Collections.singletonList(input), option);
        notEmpty(embeddings, "The embedding cannot be empty.");
        return embeddings.get(0);
    }

    /**
     * 根据可选参数，调用嵌入模型批量生成嵌入向量。
     *
     * @param inputs 表示用户输入的 {@link List}{@code <}{@link String}{@code >}。
     * @param option 表示嵌入模型可选参数的 {@link EmbedOption}。
     * @return 表示模型生成嵌入响应的 {@link List}{@code <}{@link Embedding}{@code >}。
     */
    List<Embedding> generate(List<String> inputs, EmbedOption option);
}
```

| 配置项| 描述 |
| --- | --- |
| model | 表示嵌入模型名称。 |
| apiKey | 表示嵌入模型服务密钥。 |

调用嵌入模型具体示例请看[《快速入门指南》](../quick-start-guide)的检索增强生成部分。
