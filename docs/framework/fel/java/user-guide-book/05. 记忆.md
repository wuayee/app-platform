一个任务的完成通常需要与 LLM 进行多次的交互。然而，默认情况下，LLM 是无状态的，这意味着对于每个传入的查询，它都会独立处理，不考虑其他交互。唯一存在的是当前输入，没有其他内容，导致我们无法与 LLM 进行自然连续的交互。为解决此问题，引入了记忆（Memory）。

``` java
public interface Memory {
    /**
     * 插入一条历史记录。
     *
     * @param message 表示问题描述的 {@link ChatMessage}。
     */
    void add(ChatMessage message);

    /**
     * 设置历史记录。
     *
     * @param messages 表示历史记录的 {@link List}{@code <}{@link ChatMessage}{@code >}。
     */
    void set(List<ChatMessage> messages);

    /**
     * 清空历史记录。
     */
    void clear();

    /**
     * 获取历史记录的问答对列表。
     *
     * @return 表示问答对列表的 {@link List}{@code <}{@link ChatMessage}{@code >}。
     */
    List<ChatMessage> messages();

    /**
     * 获取历史记录格式化的文本。
     *
     * @return 表示历史记录文本的 {@link String}。
     */
    String text();
}
```

Memory 实际上类似于缓存，存放最近的历史记录。以下是 Memory 的简单内存实现示例。

``` java
public class CacheMemory implements Memory {
    private List<ChatMessage> messages = new ArrayList<>();
    private final BulkStringTemplate bulkTemplate;
    private final Function<ChatMessage, Map<String, String>> extractor;

    // 省略构造方法。

    @Override
    public void add(ChatMessage message) {
        this.messages.add(message);
    }

    @Override
    public void set(List<ChatMessage> messages) {
        this.messages = new ArrayList<>(messages);
    }

    @Override
    public void clear() {
        this.messages.clear();
    }

    @Override
    public List<ChatMessage> messages() {
        return Collections.unmodifiableList(this.messages);
    }

    @Override
    public String text() {
        return this.messages.stream()
                .map(this.extractor)
                .collect(Collectors.collectingAndThen(Collectors.toList(), this.bulkTemplate::render));
    }
}
```
