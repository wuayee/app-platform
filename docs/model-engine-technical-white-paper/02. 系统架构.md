## 2.1 总体架构

![image](../resources/model-engine-technical-white-paper/2%20system-architecture/overall.png)

1. **​低代码编排：​**使用图形化界面来设计和实施复杂的 AI 应用流程，而无需深入到代码层面。这使得非技术用户如产品经理能够通过拖放组件和设置参数来构建 AI 应用。这种方式极大降低了技术门槛，加快了开发过程，并使得更多用户能够参与到 AI 解决方案的创造中。
2. **​BPM 与响应式引擎：​**而 Waterflow 的设计融合了图形化和响应式设计元素，这不仅提供了视觉上的编辑方式，同时也支持响应式编程范式，使得数据流的处理更加动态和灵活。Waterflow 兼容的图形界面让用户能够直观地看到数据流的每一步操作，而响应式设计则允许系统根据输入数据的变化实时调整处理逻辑。此外，Waterflow 还融合了业务流程管理（BPM）的概念，它允许定义一系列的业务逻辑步骤和决策点，从而管理更为复杂的业务场景。这种设计不仅提高了 AI 应用的灵活性，还强化了其在企业流程自动化中的应用能力。通过将 BPM 流程与 AI 功能结合，Waterflow 提供了一个强大的工具，支持从简单的数据处理到复杂的决策支持和自动化任务的全范围业务需求。
3. **​FEL 标准原语：​**构建在 Waterflow 之上的超集，FEL（FIT Expression for LLM）语义被用来解析和执行基于大模型的操作。这包括生成语句（generate）、对话（converse）、检索（retrieve）、代理（delegate）等操作。
4. **​FIT 调度：​**提供了高度灵活和功能强大的后端服务，支持包括动态路由、数据就近处理、多语言融合编程、插件化开发以及聚散部署等特性：

  - **​动态路由：​**除了典型 LBS 服务，FIT调度能够根据参数选择不同的函数实现，实现分布式多态能力。
  - **​数据就近处理：​**为了提高数据处理速度并减少延迟，FIT 调度系统采用了数据就近原则，优先在数据所在的物理位置附近的服务器上进行处理。而这些数据通过共享内存方式被 FIT 智能调度，避免了在函数调用中的大量的序列化，反序列化以及网络传输消耗。
  - **​多语言融合编程：​**FIT 调度支持多种编程语言，如 Python、Java、C 和 C++ 等，允许开发者根据具体需求选择合适的编程语言。FIT 函数调用中，屏蔽了目标实现语言细节，由于 FIT 的动态调度特性，真正的实现函数只有在运行时才会命中。
  - **​插件化开发：​**插件化开发允许所有算子服务像函数即服务（FaaS）一样，被开发成独立的发布单位。这种方式为开发者提供了极大的灵活性，使他们可以根据需要将一个或多个算子单独封装，也可以选择将多个相关的算子组合到一个应用中进行集中开发。这种模块化的方法不仅简化了开发和部署过程，还提高了维护的效率，因为每个算子或算子集都可以独立更新和管理，而不影响其他部分的功能。
  - **​聚散部署：​**在 Model Engine 的 FIT 调度系统中，插件化开发支持了一种灵活的聚散部署方式。这种部署策略允许算子发布单元（如 A 算子和 B 算子）以两种方式部署：它们可以聚合在一个单一的大型应用中部署，也可以各自独立部署在不同的容器中。
    当算子发布单元聚合在一起部署时，即所有相关的算子都在同一个应用环境中运行，它们之间的调用如 A 调用 B，将通过内存中直接调用来执行，这种方式提高了执行效率并减少了调用延迟。而当算子分散部署时，如 A 和 B 分别部署在不同的容器里，A 算子调用 B 算子的操作将自动转化为远程调用。这种远程调用虽然可能增加一些通信开销，但提供了更高的灵活性和可扩展性。
    FIT 引擎在这一过程中扮演了关键角色，它自动判断和执行这些部署和调用变化，无需开发者手动更改代码。这种智能的自动化处理极大地简化了运维工作，使开发者可以专注于算子的逻辑和性能优化，而不是部署的细节。这样的设计不仅提高了系统的可维护性，也加强了其适应不同运行环境的能力。
5. **​共享内存：​**在 FIT 系统中，函数调用的参数类型被自动识别，对于字符串（string）和字节序列（byte[]）类型的参数，系统会自动将其放入共享内存中。这种共享内存机制显著减少了函数调用中数据传输的内存消耗。共享内存是按节点来组织的，节点上的所有容器可以共享这部分内存。当需要跨节点传输数据时，使用远程直接内存访问（RDMA）技术来复制数据，从而优化性能并减少延迟。为了避免在使用共享内存时发生数据的反序列化操作，共享内存数据格式采用了 flatbuffers 格式，确保了不同语言对该数据格式的有效识别和高效访问。

## 2.2 设计原则

![image](../resources/model-engine-technical-white-paper/2%20system-architecture/design-principle.png)

Model Engine 的核心设计原则围绕提供一个灵活且强大的流式编程框架，以适应大模型应用的特定需求。该设计的核心思想如下：

1. **​流式编程与响应式驱动：​**Model Engine 采用流式编程模式，这非常适合处理大模型推理中的典型流特征，即连续的问题与答案交互。这种方式使得数据处理能够即时响应，实现数据流的实时处理与分析。
2. **​结合传统 BPM：​**除了支持现代的响应式编程外，Model Engine 还融合了传统的业务流程管理（BPM）功能。这一点体现了它能够处理更复杂、多阶段的业务流程，使其不仅限于自动化处理，还能够通过流程设计来优化和简化业务逻辑。
3. **​多场景适应性：​**Model Engine 的设计不局限于特定的应用场景，而是旨在通过单一的引擎支持广泛的应用，包括大模型的训练、推理及其他数据密集型任务。这种一体化的流处理引擎（Waterflow）提供了高度的可扩展性和定制性。
4. **​人工干预的可行性：​**在自动化的流程中加入人工干预的可能性，以应对需要人为决策和审查的场景。这一设计原则保证了在必要时，系统的操作可以被适当地调整或控制，以适应复杂或非标准的操作需求。
5. **​高效的内存和资源管理：​**Model Engine 通过高效的内存管理和数据就近处理策略，确保了在执行大规模计算和数据处理时的高效性和响应速度。

通过这些设计原则，Model Engine 旨在提供一个强大而灵活的工具，以满足现代 AI 驱动应用的复杂需求，特别是在处理大规模数据和复杂业务流程时的高效性和可靠性。这些原则指导了平台的发展，确保其能在多变的技术环境中持续适应和创新。

## 2.3 工作原理解析

![image](../resources/model-engine-technical-white-paper/2%20system-architecture/working-principle-analysis.png)

1. **​FEL 原语编写训推代码：​**使用 FEL（FIT Expression for LLM）原语，开发者可以编写处理数据和模型推理的代码。这种高级编程抽象简化了复杂模型的实现，使得开发者可以更专注于业务逻辑而非底层实现。
2. **​响应式代码自动成流程：​**在 Waterflow 引擎中，编写的响应式代码自动转换为数据流程，这意味着代码直接映射到数据处理流中。每一段代码都对应流中的一个节点，如图中的 `mapper`、`splitter` 和 `indexer`，确保数据流动性和处理的连贯性。
3. **​为模型系统性能差异设置背压：​**Waterflow 引擎支持背压管理，这允许系统根据处理节点的性能自动调整数据流速度。例如，如果某一节点处理能力不足以应对高速数据流，系统会自动减慢数据供应速度，防止数据溢出或处理延迟。
4. **​无代码侵入内存共享机制：​**系统采用了高效的内存管理策略，允许不同的处理节点在不进行代码更改的情况下共享内存。如图中所示，通过 RDMA 技术，不同服务器的数据可以快速传输且共享处理，大幅度提高了数据处理效率。
5. **​原语调度标准算子接口：​**每个处理节点如 `mapper`、`splitter` 等都遵循标准算子接口，这样的设计使得每个组件都可以在不同的应用中复用，提高了系统的模块化和灵活性。
6. **​不同算子接口发展各自生态：​**不同的算子接口，也就是 Model Engine 的产出物（工具）可以根据其特定功能发展独立的生态系统。工具生态系统被细分为几个关键类别，以支持各种功能和优化大模型的集成及运行效率：

  - **​函数算子：​**这些是基本的处理单元，用于执行数据转换、处理和分析。函数算子通常是通用的，可以在多种数据流场景中重复使用。
  - **​大模型对接适配器：​**专门设计用来连接和管理大模型的算子。这些适配器确保大模型能够与系统其他部分无缝对接，处理输入和输出数据，同时优化模型的加载和执行效率。
  - **​知识库存储对接适配器：​**这类工具专为对接外部知识库或内部存储系统而设计，使得数据和知识库可以灵活地被查询和更新，支持复杂的信息检索和数据持久化操作。
  - **​RAG 工具：​**检索增强生成（RAG）工具专门用于增强大模型的生成能力，通过从外部知识源检索信息来丰富和指导模型的响应生成。
  - **​智能体工具：​**这些工具使得模型能够表现出更复杂的行为和决策能力，常用于构建高级交互式应用和工具调用。
