![image](../resources/model-engine-technical-white-paper/3%20fit/overall.png)

## 3.1 多语言融合编程

![image](../resources/model-engine-technical-white-paper/3%20fit/multi-language.png)

1. **​Genericable：​**是基于函数的抽象概念，采用一份统一的领域特定语言（DSL）进行描述。这种抽象不仅定义了功能的框架和接口，还规定了如何通过特定的 DSL 来实现这些功能，为多种语言提供了统一的基础。
2. **​Fitable：​**与“Genericable”抽象相对应的是“Fitable”，它表示对同一个抽象可以有不同的实现。每个“Fitable”实体是“Genericable”定义的具体实现，这些实现可以通过不同的编程语言来完成，如图中的 C、Java 和 Python。
3. **​Multi-Language：​**不同的“Fitable”实现可以采用不同的编程语言实现，这体现了平台的灵活性和开放性。例如，一个基于“Genericable”的函数可以用 Java、Python、C/C++ 等不同语言实现，满足不同开发者的需求和优化特定语言的性能。
4. **​Distributed-Polymorphic：​**在分布式系统中实现多态性，通过如函数 ID 匹配、参数匹配等方式进行路由决策。这允许系统根据调用的上下文动态选择最适合的实现，从而优化执行效率和资源使用。

## 3.2 插件化开发

![image](../resources/model-engine-technical-white-paper/3%20fit/plugin.png)

1. **​FIT Runtime：​**FIT 平台为每种支持的编程语言提供了专门的运行时环境，称为 FIT Runtime。这些运行时环境作为插件加载器，负责加载各自语言编写的可执行文件。例如，有专门的 FIT Runtime for Java、FIT Runtime for C/C++、以及 FIT Runtime for Python，分别加载 Java、C/C++ 和 Python 语言的插件。
2. **​独立进程：​**每个 FIT Runtime 运行在一个独立的进程中。这样设计有助于隔离各个运行时环境，确保它们之间不会相互干扰，同时也提高了系统的稳定性和安全性。
3. **​进程间通讯：​**FIT Runtime 之间通过进程间通讯（IPC）机制进行数据和命令的交换。通讯协议的选择非常灵活，可以根据需要使用 HTTP、gRPC、RDMA 等不同的通讯插件来实现。
4. **​本地调用优先：​**当 FIT Runtime 命中某个提供服务的方法时，会优先进行本地调用。这意味着如果所需功能已在本地运行时环境中加载，系统会直接调用，避免不必要的跨进程或网络通信，从而提高响应速度和效率。
5. **​热插拔机制：​**FIT Runtime 支持热插拔机制，允许在系统运行时动态地加载或卸载插件。这种机制提供了极高的灵活性，使得系统可以根据需要随时添加或移除功能。不过，不同编程语言对这一特性的支持程度可能有所不同，这取决于语言本身的动态加载能力。

## 3.3 聚散部署

![image](../resources/model-engine-technical-white-paper/3%20fit/micro-mono-deploy.png)

1. **​蚂蚁模式（散部署）：​**在蚂蚁模式中，每个 FIT Runtime 仅加载一个插件。例如：
   a) 一个 FIT Runtime 加载一个插件 A，形成部署单元 Deploy Unit A（DA）。
   b) 另一个 FIT Runtime 加载一个插件 B，形成部署单元 Deploy Unit B（DB）。
   每个部署单元分别形成各自的集群，并独立提供服务。这种部署方式称为散部署，它允许每个服务保持高度独立性，易于管理和扩展，适用于需要高度模块化和独立扩展的场景。

> *在此模式中，每个运行时环境与恰好一个插件关联，并形成独立的部署单元。表示如下：*
>
> - *设 R 为运行时环境集合，*
> - *P 为插件集合，*
> - *d 为将每个运行时映射到一个单独插件的函数，形成唯一的部署单元。*
>
> *部署可表示为：d:R→P*
> *其中，R 中的每个元素（运行时）唯一映射到  P 中的一个元素（插件），形成独立的集群。*

2. **​大象模式（聚部署）：​**在大象模式中，每个 FIT Runtime 可以加载多个插件，形成一个更大的部署单元。例如：
   a) 一个 FIT Runtime 加载多个插件（A1, A2, A3...），形成部署单元 Deploy Unit A（DA）。
   b) 另一个 FIT Runtime 加载多个插件（B1, B2, B3...），形成部署单元 Deploy Unit B（DB）。
   每个部署单元也形成各自的集群，但它们包含多个插件。这种部署方式称为聚部署，它适用于功能或服务高度相关的场景，可以减少运维成本，提高资源使用效率。

> *在此模式中，每个运行时可以加载多个插件。表示如下：*
>
> - *R 为运行时环境集合，*
> - *P 为插件集合，*
> - *D 为部署单元集合，*
> - *f:R→P(P)（其中 P(P) 是 P 的幂集），将每个运行时映射到一组插件。*
>
> *部署函数为：f(r)={p1,p2,...,pn} 对每个 r∈R*
> *这里每个运行时 r 关联了一组插件，形成更大的集群。*

3. **​野兽模式（全量部署）：​**野兽模式是一种更为集中和综合的部署方式，一个 FIT Runtime 加载多种插件（A1, A2, A3...B1, B2, B3...），形成一个大的部署单元 Deploy Unit（DAB）。
   DAB 形成一个大集群，其中一部分节点（m 台）提供 DA 服务，另一部分节点（n 台）提供 DB 服务。
   这种部署模式称为全量部署，它将所有相关服务集中在一个大集群中，可以通过不同的节点分片来提供服务，适用于需要大规模资源共享和高效能协同工作的场景。

> *在此模式中，单个运行时可以处理所有插件，服务通过不同节点分布。表示如下：*
>
> - *R 为单个运行时，*
> - *P 为所有插件集合，*
> - *S 为所有服务类型集合，*
> - *g:S→P(P)×N，其中 N 表示分配给每种服务类型的节点数。*
>
> *部署可以描述为：g(s)=({p1,p2,...},n) 其中 s 是服务类型，{p1,p2,...} 是处理该服务的插件子集，n 是在运行时内为此服务分配的节点数。*

以上三种部署模式各有其特点和适用场景，FIT平台通过这种灵活的聚散部署策略，可以满足不同规模和需求的应用场景，提供高效、灵活的服务解决方案。

## 3.4 共享内存

在大模型应用中，由于需要处理海量的数据，数据的复制和传输会引起显著的内存消耗和性能损耗。为了解决这一问题，FIT 引擎引入了共享内存机制。这种机制在同一物理机内部实现了数据的零拷贝传输，即在不同的算子和容器之间传递数据时，不需要进行实际的数据复制操作，从而大大减少了内存的消耗。

FIT 引擎还通过自动识别和分配共享内存，确保了数据传输的高效性。开发人员在使用过程中不需要关注内存的具体分配和管理，从而无感知地享受系统性能的提升。此外，FIT 引擎采用高性能的序列化和反序列化方法，进一步优化了数据的处理速度和效率。

这些技术手段不仅减少了内存的使用，还显著提高了系统的整体性能，使得大规模的 AI 数据处理更为高效。通过这种方式，FIT 引擎在处理复杂大模型应用时，能够保持高效、稳定的性能表现，增强了系统的竞争力。

![image](../resources/model-engine-technical-white-paper/3%20fit/shared-memory.png)

以清洗一个文件夹为例，描述共享内存如何在玉简体系中保证内存消耗的最小：

1. **文件读入与共享内存分配（自动共享内存识别）：**

   路由策略将文件数据读入系统，并将其放入目标节点的共享内存中。文件数据根据算子集群的复杂性，被分配到不同的节点，如 node1 和 node2。
2. **内存标识符与数据总线（databus）：**

   内存标识符被封装在数据总线相关类型中，这样消费者不需要感知具体的内存地址。数据总线负责管理和调度内存数据，简化了算子的开发和维护。
3. **节点调度与内存地址识别（共享内存识别）：**

   调度节点能够识别内存地址，并将相应的算子调度到目标节点进行处理。例如，OCR 算子会被调度到包含其所需数据的节点。
4. **分块数据处理与零拷贝（数据就近）：**

   文件数据可能被分块并分配到不同的算子节点。调度节点优先将算子调度到包含对应内存块的节点执行，从而实现数据的零拷贝处理。这确保了多容器、多算子实例并发执行时的数据处理效率。
5. **远程数据传输（RDMA）：**

   当算子需要在不同节点间移动时，数据总线使用远程直接内存访问（RDMA）技术将数据高效传输到算子所在节点。这种方法减少了数据传输延迟和资源消耗，确保了数据处理的实时性。
